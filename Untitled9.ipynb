{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nida07/college-chatbot-RNN/blob/master/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PI-XkJaWP0EQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62d9bb0c-3fb2-4a27-f369-0788c171a9c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensorflow is an open source for the ml framework, helping in training, building the model which provide API keras\n"
      ],
      "metadata": {
        "id": "YIaXbOA7JvaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQL18WWPP4LY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('/content/intents.json', 'r') as file:\n",
        "    intents = json.load(file)\n",
        "\n",
        "# Preprocess data\n",
        "patterns = []\n",
        "responses = []\n",
        "tags = []\n",
        "\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        patterns.append(pattern)\n",
        "        responses.append(intent['responses'][0])  # We'll just use the first response for simplicity\n",
        "        tags.append(intent['tag'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04E_6UdXQ6N_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# padding sequences to a fixed length, tokenizing text data\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Tokenize input patterns\n",
        "tokenizer = Tokenizer()\n",
        "#vocabulary, input patterns, and numerical indices based on word repetition\n",
        "tokenizer.fit_on_texts(patterns)\n",
        "#  word index dictionary from the tokenizer\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(patterns)\n",
        "# max number of sequences in each length and find the maximum and it set as pad_sequences\n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "\n",
        "# Pad sequences to have same length add 0 after ie; padding = 'post' so each sequence will be same length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_len, padding='post')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qSGDTQZRSnk"
      },
      "outputs": [],
      "source": [
        "# # LabelEncoder is used to convert categorical labels into numerical labels.\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# # Convert tags to numerical labels\n",
        "# label_encoder = LabelEncoder()\n",
        "# encoded_tags = label_encoder.fit_transform(tags)\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(padded_sequences, encoded_tags, epochs=100, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSK6ZPQAEG8c"
      },
      "outputs": [],
      "source": [
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2KEdyFeQ_Vo",
        "outputId": "b364f42f-b922-48b8-c36d-83d5fe77fa96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 3s 17ms/step - loss: 5.9522 - accuracy: 0.0469\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 4.9951 - accuracy: 0.0667\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 3.6512 - accuracy: 0.0593\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5496 - accuracy: 0.0667\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5271 - accuracy: 0.0494\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 3.5164 - accuracy: 0.0642\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5231 - accuracy: 0.0568\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5225 - accuracy: 0.0420\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 3.5110 - accuracy: 0.0667\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5181 - accuracy: 0.0519\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5175 - accuracy: 0.0593\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5117 - accuracy: 0.0642\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5143 - accuracy: 0.0617\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5068 - accuracy: 0.0667\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 3.5136 - accuracy: 0.0494\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5091 - accuracy: 0.0593\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5080 - accuracy: 0.0593\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 3.5088 - accuracy: 0.0543\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5054 - accuracy: 0.0543\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5092 - accuracy: 0.0593\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 3.5088 - accuracy: 0.0642\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5011 - accuracy: 0.0691\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.5089 - accuracy: 0.0444\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 3.4919 - accuracy: 0.0642\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 3.4897 - accuracy: 0.0667\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 3.4768 - accuracy: 0.0543\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.4525 - accuracy: 0.0469\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 3.4167 - accuracy: 0.0691\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 3.3457 - accuracy: 0.0815\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 3.1926 - accuracy: 0.1111\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 3.0521 - accuracy: 0.1086\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 2.9082 - accuracy: 0.1284\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 2.7965 - accuracy: 0.1778\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 2.7020 - accuracy: 0.1679\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 2.6406 - accuracy: 0.1654\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 2.5654 - accuracy: 0.1926\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 2.5041 - accuracy: 0.2049\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 2.4562 - accuracy: 0.1901\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 2.3866 - accuracy: 0.1926\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 2.3077 - accuracy: 0.2420\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 2.2467 - accuracy: 0.2642\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 34ms/step - loss: 2.2148 - accuracy: 0.2198\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 31ms/step - loss: 2.1686 - accuracy: 0.2642\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 31ms/step - loss: 2.1170 - accuracy: 0.2914\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 33ms/step - loss: 2.0380 - accuracy: 0.3358\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 29ms/step - loss: 1.9572 - accuracy: 0.3802\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.9056 - accuracy: 0.3407\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 1.8423 - accuracy: 0.3877\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.7861 - accuracy: 0.3506\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.7077 - accuracy: 0.4123\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.6716 - accuracy: 0.4321\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.6178 - accuracy: 0.4765\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.5619 - accuracy: 0.4667\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.5170 - accuracy: 0.4864\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.4574 - accuracy: 0.5531\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.4590 - accuracy: 0.5062\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.4276 - accuracy: 0.5136\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.3368 - accuracy: 0.6025\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.3103 - accuracy: 0.6000\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.2477 - accuracy: 0.5852\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.2064 - accuracy: 0.6222\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.1917 - accuracy: 0.6025\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.1343 - accuracy: 0.6370\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0948 - accuracy: 0.6346\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.0660 - accuracy: 0.6840\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.0131 - accuracy: 0.6938\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9607 - accuracy: 0.7284\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9304 - accuracy: 0.7654\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.8753 - accuracy: 0.7506\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.8235 - accuracy: 0.8025\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.7870 - accuracy: 0.8025\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.7710 - accuracy: 0.8198\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.7407 - accuracy: 0.7926\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.6981 - accuracy: 0.8321\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.6639 - accuracy: 0.8593\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.6189 - accuracy: 0.8667\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.5739 - accuracy: 0.8840\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.5305 - accuracy: 0.9012\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.5268 - accuracy: 0.9062\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.4858 - accuracy: 0.9136\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.4696 - accuracy: 0.9136\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.4615 - accuracy: 0.9136\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.4323 - accuracy: 0.9160\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.4000 - accuracy: 0.9235\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.3633 - accuracy: 0.9383\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.3455 - accuracy: 0.9383\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.3170 - accuracy: 0.9506\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 31ms/step - loss: 0.2985 - accuracy: 0.9580\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 31ms/step - loss: 0.2807 - accuracy: 0.9630\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 29ms/step - loss: 0.2692 - accuracy: 0.9531\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 31ms/step - loss: 0.2507 - accuracy: 0.9704\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 35ms/step - loss: 0.2360 - accuracy: 0.9654\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 1s 47ms/step - loss: 0.2248 - accuracy: 0.9704\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 32ms/step - loss: 0.2129 - accuracy: 0.9753\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.2020 - accuracy: 0.9778\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.1887 - accuracy: 0.9753\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.1781 - accuracy: 0.9827\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.1682 - accuracy: 0.9852\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.1586 - accuracy: 0.9852\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 0.1517 - accuracy: 0.9852\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f8d7d6e5480>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sequential is a class for creating a linear stack of layers. Embedding, LSTM,\n",
        "# and Dense are classes representing the layers\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# layers 3\n",
        "# Embedding(input dim, output dimension, input_length)\n",
        "# lstm uses 128 memory cell\n",
        "# dense (tot no of tags , activation function)\n",
        "\n",
        "\n",
        "# Define model architecture\n",
        "model = Sequential([\n",
        "    Embedding(len(word_index) + 1, 64, input_length=max_sequence_len),\n",
        "    LSTM(128),\n",
        "    Dense(len(tags), activation='softmax')\n",
        "])\n",
        "\n",
        "# adaptive moment estimation increase learning rate\n",
        "# loss is multiclass integer-based, optimizer update model weight, accuracy evaluation\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model(input,target label,epoch verbos)\n",
        "model.fit(padded_sequences, encoded_tags, epochs=100, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QiHpV6_Eqot"
      },
      "outputs": [],
      "source": [
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq5tZiv4UOY-"
      },
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# # Convert tags to numerical labels\n",
        "# label_encoder = LabelEncoder()\n",
        "# encoded_tags = label_encoder.fit_transform(tags)\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(padded_sequences, encoded_tags, epochs=100, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP9VIoP6U5Ft"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def chat():\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"c u later!!\")\n",
        "            break\n",
        "\n",
        "        # Tokenize user input\n",
        "        input_seq = tokenizer.texts_to_sequences([user_input])\n",
        "        padded_input_seq = pad_sequences(input_seq, maxlen=max_sequence_len, padding='post')\n",
        "\n",
        "        # Predict probabilities for each class\n",
        "        predicted_probs = model.predict(padded_input_seq)\n",
        "\n",
        "        # Get predicted tag\n",
        "        predicted_tag_index = np.argmax(predicted_probs)\n",
        "        predicted_tag = label_encoder.inverse_transform([predicted_tag_index])[0]\n",
        "\n",
        "        # Get response\n",
        "        responses_list = [responses[i] for i, tag in enumerate(tags) if tag == predicted_tag]\n",
        "        print(\"Bot:\", np.random.choice(responses_list))\n",
        "\n",
        "# Start chatting\n",
        "chat()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyVjyEs8u_ge",
        "outputId": "b45f930a-f6c9-47fc-a7fc-4abf2b5ab5db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "81/81 [==============================] - 1s 2ms/step - loss: 3.5397 - accuracy: 0.1451\n",
            "Epoch 2/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 3.1552 - accuracy: 0.3549\n",
            "Epoch 3/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 2.6483 - accuracy: 0.4228\n",
            "Epoch 4/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 2.1117 - accuracy: 0.6728\n",
            "Epoch 5/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.6084 - accuracy: 0.8333\n",
            "Epoch 6/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 1.1894 - accuracy: 0.8981\n",
            "Epoch 7/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.8582 - accuracy: 0.9383\n",
            "Epoch 8/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.9630\n",
            "Epoch 9/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.9753\n",
            "Epoch 10/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.9815\n",
            "Epoch 11/100\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.2603 - accuracy: 0.9877\n",
            "Epoch 12/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.2029 - accuracy: 0.9877\n",
            "Epoch 13/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.1619 - accuracy: 0.9938\n",
            "Epoch 14/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.1100 - accuracy: 0.9938\n",
            "Epoch 16/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9969\n",
            "Epoch 17/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9969\n",
            "Epoch 19/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9969\n",
            "Epoch 20/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.7325e-04 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.2266e-04 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.8007e-04 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 8.3495e-04 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 7.9263e-04 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 7.5905e-04 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 7.1882e-04 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 6.8570e-04 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 6.5431e-04 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 6.2463e-04 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 5.9069e-04 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 5.7184e-04 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 5.4020e-04 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 5.1532e-04 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 4.9216e-04 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 4.6627e-04 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 4.4749e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a06a1c56050>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load data from intents.json\n",
        "with open('intents.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract patterns and tags from the dataset\n",
        "patterns = []\n",
        "tags = []\n",
        "responses = []\n",
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        patterns.append(pattern)\n",
        "        tags.append(intent['tag'])\n",
        "        responses.append(intent['responses'][0])  # Assuming we'll use the first response\n",
        "\n",
        "# Tokenize input patterns\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(patterns).toarray()\n",
        "\n",
        "# Encode tags into numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(tags)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and train the model\n",
        "model = Sequential([\n",
        "    Dense(128, input_shape=(X_train.shape[1],), activation='relu'),\n",
        "    Dense(len(set(y)), activation='softmax')\n",
        "])\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=4, verbose=1)\n",
        "\n",
        "# # Function to interact with the chatbot\n",
        "# def chat():\n",
        "#     while True:\n",
        "#         user_input = input(\"You: \")\n",
        "#         if user_input.lower() == 'quit':\n",
        "#             break\n",
        "\n",
        "#         # Tokenize user input\n",
        "#         user_input_vec = vectorizer.transform([user_input]).toarray()\n",
        "\n",
        "#         # Predict tag\n",
        "#         predicted_tag = model.predict_classes(user_input_vec)\n",
        "\n",
        "#         # Get response\n",
        "#         response_index = np.where(y_train == predicted_tag)[0][0]\n",
        "#         print(\"Bot:\", responses[response_index])\n",
        "\n",
        "# # Start chatting\n",
        "# chat()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE1cBF9OxSRH",
        "outputId": "4307c828-c109-4bfb-ca24-28be38a0bdbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hello\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "Bot: Hello!\n",
            "You: number\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Bot: Sad to see you go :(\n",
            "You: bye\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Bot: Hello!\n",
            "You: bye\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Bot: Hello!\n",
            "You: college time\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Bot: Hello!\n",
            "You: quit\n"
          ]
        }
      ],
      "source": [
        "# Function to interact with the chatbot\n",
        "def chat():\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'quit':\n",
        "            break\n",
        "\n",
        "        # Tokenize user input\n",
        "        user_input_vec = vectorizer.transform([user_input]).toarray()\n",
        "\n",
        "        # Predict probabilities for each class\n",
        "        predicted_probs = model.predict(user_input_vec)\n",
        "\n",
        "        # Get the index of the class with the highest probability\n",
        "        predicted_tag_index = np.argmax(predicted_probs)\n",
        "\n",
        "        # Get response\n",
        "        response_index = np.where(y_train == predicted_tag_index)[0][0]\n",
        "        print(\"Bot:\", responses[response_index])\n",
        "\n",
        "# Start chatting\n",
        "chat()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXYWL6oFx1kP"
      },
      "outputs": [],
      "source": [
        "# Function to interact with the chatbot\n",
        "def chat():\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'quit':\n",
        "            break\n",
        "        elif user_input.strip() == '':\n",
        "            print(\"Bot: Please provide input.\")\n",
        "            continue\n",
        "\n",
        "        # Tokenize user input\n",
        "        user_input_vec = vectorizer.transform([user_input]).toarray()\n",
        "\n",
        "        # Predict probabilities for each class\n",
        "        predicted_probs = model.predict(user_input_vec)\n",
        "\n",
        "        # Get the index of the class with the highest probability\n",
        "        predicted_tag_index = np.argmax(predicted_probs)\n",
        "\n",
        "        # Get response\n",
        "        if predicted_tag_index < len(responses):  # Check if index is within range\n",
        "            response_index = np.where(y_train == predicted_tag_index)[0][0]\n",
        "            print(\"Bot:\", responses[response_index])\n",
        "        else:\n",
        "            print(\"Bot: I'm sorry, I didn't understand that.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDEehLJNx5Dn",
        "outputId": "94662e98-2714-49f2-fabb-b12692f71045"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "Bot: Hello!\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Bot: Sad to see you go :(\n",
            "Bot: Please provide input.\n",
            "You: quit\n"
          ]
        }
      ],
      "source": [
        "chat()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+NN6RkkTfKwJs8eaKGCcL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}